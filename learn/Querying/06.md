# Prometheus Cheat Sheet - Basics (Metrics, Labels, Time Series, Scraping)

* https://iximiuz.com/en/posts/prometheus-metrics-labels-time-series/

Here we focus on the most basic Prometheus concepts - metrics, labels, scrapes, and time series.

## What is a metric?

In Prometheus, everything revolves around [*metrics*](https://prometheus.io/docs/concepts/data_model/). A *metric* is a feature (i.e., a characteristic) of a system that is being measured. Typical examples of metrics are:
在 Prometheus 中，一切都围绕指标展开。 度量是被测量系统的一个特征（即特征）。 指标的典型示例有：

- http_requests_total
- http_request_size_bytes
- system_memory_used_bytes
- node_network_receive_bytes_total

![Prometheus metrics](https://iximiuz.com/prometheus-metrics-labels-time-series/metrics-2000-opt.png "Prometheus metrics")

## What is a label?

The idea of a *metric* seems fairly simple. However, there is a problem with such simplicity. On the diagram above, Prometheus monitors several application servers simultaneously. Each of these servers reports `mem_used_bytes` metric. At any given time, how should Prometheus store multiple samples behind a single metric name?
度量的想法似乎相当简单。 然而，这种简单性存在一个问题。 在上图中，Prometheus 同时监控多个应用程序服务器。 这些服务器中的每一个都会报告 mem_used_bytes 指标。 在任何给定时间，Prometheus 应如何在单个指标名称后面存储多个样本？

The first option is *aggregation*. Prometheus could sum up all the bytes and store the total memory usage of the whole fleet. Or compute an average memory usage and store it. Or min/max memory usage. Or compute and store all of those together. However, there is always a problem with storing only aggregated metrics - we wouldn't be able to pin down a particular server with a bizarre memory usage pattern based on such data.
第一个选项是聚合。 Prometheus 可以汇总所有字节并存储整个队列的总内存使用量。 或者计算平均内存使用量并存储它。 或最小/最大内存使用量。 或者计算并将所有这些存储在一起。 然而，仅存储聚合指标始终存在一个问题 - 我们无法根据此类数据确定具有奇怪内存使用模式的特定服务器。

Luckily, Prometheus uses another approach - it can differentiate samples with the same metric name by labeling them. A *label* is a certain attribute of a metric. Generally, labels are populated by metric producers (servers in the example above). However, in Prometheus, it's possible to enrich a metric with some static labels based on the producer's identity while recording it on the Prometheus node's side. In the wild, it's common for a Prometheus metric to carry multiple labels.
幸运的是，Prometheus 使用了另一种方法 - 它可以通过标记来区分具有相同度量名称的样本。 标签是度量的特定属性。 通常，标签由指标生产者（上例中的服务器）填充。 然而，在 Prometheus 中，可以根据生产者的身份使用一些静态标签来丰富指标，同时将其记录在 Prometheus 节点一侧。 在野外，普罗米修斯指标带有多个标签是很常见的。

Typical examples of labels are:

- instance - an *instance* (a server or cronjob process) of a *job* being monitored in the `<host>:<port>` form
- job - a name of a logical group of *instances* sharing the same purpose
- endpoint - name of an HTTP API endpoint
- method - HTTP method
- status_code - HTTP status code

![Prometheus labels](https://iximiuz.com/prometheus-metrics-labels-time-series/labels-2000-opt.png "Prometheus labels")

## What is scraping?

There are two principally different approaches to collect metrics. A monitoring system can have a *passive* or *active* collector component. In the case of a passive collector, samples are constantly *pushed* by active instances to the collector. In contrast, an active collector periodically *pulls* samples from instances that passively expose them.
有两种主要不同的方法来收集指标。 监控系统可以具有无源或有源收集器组件。 对于被动收集器，样本不断地由主动实例推送到收集器。 相反，主动收集器会定期从被动公开样本的实例中提取样本。

Prometheus uses a *pull model*, and the metric collection process is called *scraping*.
Prometheus 采用拉模型，指标收集过程称为抓取。

In a system with a *passive collector*, there is no need to register monitored instances upfront. Instead, you need to communicate the address of the collector endpoint to the instances, so they could start pushing data. However, in the case of an *active collector*, one should supply the list of instances to be scraped beforehand. Or teach the monitoring system how to build such a list dynamically using one of the supported service discovery mechanisms.
在具有被动收集器的系统中，无需预先注册受监控的实例。 相反，您需要将收集器端点的地址传达给实例，以便它们可以开始推送数据。 但是，如果是活动收集器，则应预先提供要抓取的实例列表。 或者教导监控系统如何使用支持的服务发现机制之一动态构建这样的列表。

In Prometheus, scraping is configured via providing a static list of `<host>:<port>` **scraping targets**. It's also possible to configure a service-discovery-specific (consul, docker, kubernetes, ec2, etc.) endpoint to fetch such a list at runtime. You also need to specify a **scrape interval** - a delay between any two consecutive scrapes. Surprisingly or not, it's common for such an interval to be several seconds or even tens of seconds long.
在 Prometheus 中，通过提供 `<host>:<port>` 抓取目标的静态列表来配置抓取。 还可以配置特定于服务发现的（consul、docker、kubernetes、ec2 等）端点以在运行时获取此类列表。 您还需要指定抓取间隔 - 任意两次连续抓取之间的延迟。 不管是否令人惊讶，这样的间隔通常长达几秒甚至几十秒。

For a monitoring system, the design choice to use a pull model and relatively long scrape intervals have some interesting repercussions...
对于监控系统，选择使用拉模型和相对较长的抓取间隔会产生一些有趣的影响...

## What is a time series in Prometheus?

**Side note 1:** Despite being born in the age of distributed systems, every Prometheus server node is autonomous. I.e., there is no distributed metric storage in the default Prometheus setup, and every node acts as a self-sufficient monitoring server with local metric storage. It simplifies a lot of things, including the following explanation, because we don't need to think of how to merge overlapping series from different Prometheus nodes* 😉
旁注 1：尽管诞生于分布式系统时代，但每个 Prometheus 服务器节点都是自治的。 即，默认的 Prometheus 设置中没有分布式指标存储，每个节点都充当具有本地指标存储的自给自足的监控服务器。 它简化了很多事情，包括下面的解释，因为我们不需要考虑如何合并来自不同 Prometheus 节点的重叠系列

![Prometheus series](https://iximiuz.com/prometheus-metrics-labels-time-series/time-series-2000-opt.png "Prometheus time series")

In general, a stream of timestamped values is called a **time series**. In the above example, there are four different time series. But only two metric names. I.e., a time series in Prometheus is defined by a combination of a metric name and a particular set of key-value labels.
一般来说，带有时间戳的值流称为时间序列。 在上面的示例中，有四个不同的时间序列。 但只有两个指标名称。 即，Prometheus 中的时间序列是由指标名称和一组特定的键值标签的组合定义的。

**Side note 2:** Values are always floating-point numbers; timestamps are integers storing the number of milliseconds since the Unix epoch.
旁注 2：值始终是浮点数； 时间戳是存储自 Unix 纪元以来的毫秒数的整数。

Every such time series is stored separately on the Prometheus node in the form of an append-only file. Since a series is defined by the label value(s), one needs to be careful with labels that might have high cardinality.
每个这样的时间序列都以仅附加文件的形式单独存储在 Prometheus 节点上。 由于系列是由标签值定义的，因此需要小心可能具有高基数的标签。

The terms *time series*, *series*, and *metric* are often used interchangeably. However, in Prometheus, a metric technically means a group of [time] series.
术语“时间序列”、“序列”和“度量”通常可以互换使用。 然而，在 Prometheus 中，度量在技术上意味着一组[时间]序列。

## Downsides of active scraping

Since it's a single node scraping multiple distributed endpoints with potentially different performance and network conditions, the exact sample timestamps will (although most of the time just slightly) vary for every scrape. Because of that and of the potential loss of some scrapes, the interval between two samples in a given time series is neither constant nor multiplication of the scrape interval. Remember the repercussions I mentioned above?
由于它是单个节点抓取具有可能不同的性能和网络条件的多个分布式端点，因此每次抓取的确切样本时间戳将会（尽管大多数时候只是略有不同）。 由于这一点以及某些刮擦的潜在损失，给定时间序列中两个样本之间的间隔既不是常数，也不是刮擦间隔的乘积。 还记得我上面提到的后果吗？

![Missing scrapes illustration](https://iximiuz.com/prometheus-metrics-labels-time-series/scrape-interval-drift-2000-opt.png)

Prometheus node scraping two services every 10 seconds - actual samples aren't ideally aligned in time.
Prometheus 节点每 10 秒抓取两个服务 - 实际样本在时间上并不理想。

There is another interesting, more important pitfall to be aware of. If a target reports a *gauge* (i.e., **instant measurement**) metric that changes more frequently than it's scraped, the intermediate values will never be seen by the Prometheus node. Thus, it may cause *blindness* of the monitoring system to some bizarre patterns:
还有另一个有趣的、更重要的陷阱需要注意。 如果目标报告的量规（即即时测量）指标的变化频率高于其抓取频率，则 Prometheus 节点将永远看不到中间值。 因此，它可能会导致监控系统对一些奇怪的模式视而不见：

Obviously, **counter** (i.e., monotonically incrementing measurement) metrics don't have such a problem.
显然，计数器（即单调递增测量）指标不存在这样的问题。

